<!DOCTYPE html>
<html lang="en"><head>
  <meta charset="utf-8">
  <meta http-equiv="X-UA-Compatible" content="IE=edge">
  <meta name="viewport" content="width=device-width, initial-scale=1"><!-- Begin Jekyll SEO tag v2.6.1 -->
<title>Computers, Ethics, and Society | HvanB</title>
<meta name="generator" content="Jekyll v3.8.5" />
<meta property="og:title" content="Computers, Ethics, and Society" />
<meta property="og:locale" content="en" />
<meta name="description" content="According to Lawler, what is “the problem of technology”? What are the moral principles that he appeals to in deploying his argument? And, to what extent do you agree or disagree with his argument?" />
<meta property="og:description" content="According to Lawler, what is “the problem of technology”? What are the moral principles that he appeals to in deploying his argument? And, to what extent do you agree or disagree with his argument?" />
<link rel="canonical" href="http://localhost:4000/2017/05/Computers-Ethics-and-Society.html" />
<meta property="og:url" content="http://localhost:4000/2017/05/Computers-Ethics-and-Society.html" />
<meta property="og:site_name" content="HvanB" />
<meta property="og:type" content="article" />
<meta property="article:published_time" content="2017-05-18T00:00:00-06:00" />
<script type="application/ld+json">
{"description":"According to Lawler, what is “the problem of technology”? What are the moral principles that he appeals to in deploying his argument? And, to what extent do you agree or disagree with his argument?","@type":"BlogPosting","url":"http://localhost:4000/2017/05/Computers-Ethics-and-Society.html","headline":"Computers, Ethics, and Society","dateModified":"2017-05-18T00:00:00-06:00","datePublished":"2017-05-18T00:00:00-06:00","mainEntityOfPage":{"@type":"WebPage","@id":"http://localhost:4000/2017/05/Computers-Ethics-and-Society.html"},"@context":"https://schema.org"}</script>
<!-- End Jekyll SEO tag -->
<link rel="stylesheet" href="/assets/main.css"><link type="application/atom+xml" rel="alternate" href="http://localhost:4000/feed.xml" title="HvanB" /></head>
<body><header class="site-header" role="banner">

  <div class="wrapper">

    <a class="site-title" href="/">HvanB</a>

    <nav class="site-nav">
      <span class="menu-icon">
        <svg viewBox="0 0 18 15" width="18px" height="15px">
          <path fill="#424242" d="M18,1.484c0,0.82-0.665,1.484-1.484,1.484H1.484C0.665,2.969,0,2.304,0,1.484l0,0C0,0.665,0.665,0,1.484,0 h15.031C17.335,0,18,0.665,18,1.484L18,1.484z"/>
          <path fill="#424242" d="M18,7.516C18,8.335,17.335,9,16.516,9H1.484C0.665,9,0,8.335,0,7.516l0,0c0-0.82,0.665-1.484,1.484-1.484 h15.031C17.335,6.031,18,6.696,18,7.516L18,7.516z"/>
          <path fill="#424242" d="M18,13.516C18,14.335,17.335,15,16.516,15H1.484C0.665,15,0,14.335,0,13.516l0,0 c0-0.82,0.665-1.484,1.484-1.484h15.031C17.335,12.031,18,12.696,18,13.516L18,13.516z"/>
        </svg>
      </span>

      <div class="trigger">
        <!--
            my_page.autogen is populated by the pagination logic for all pages
                            that are automatically created by the gem. Check for non-existence to exclude pagination pages from site.pages iterators
          -->
          
        
          
        
          
        
          
        
          
        
          
          <a class="page-link" href="/artwork/index.html">Artwork</a>
          
        
          
        
          
        
          
        
          
          <a class="page-link" href="/blog/index.html">Blog</a>
          
        
          
        
          
        
          
        
          
        
          
        
          
          <a class="page-link" href="/projects/index.html">Projects</a>
          
        
          
        
          
        
          
        
      </div>
    </nav>

  </div>

</header>
<main class="page-content" aria-label="Content">
      <div class="wrapper">
        <article class="post h-entry" itemscope itemtype="http://schema.org/BlogPosting">

  <header class="post-header">
    <h1 class="post-title p-name" itemprop="name headline">Computers, Ethics, and Society</h1>
    <p class="post-meta">
      <time class="dt-published" datetime="2017-05-18T00:00:00-06:00" itemprop="datePublished">May 18, 2017
      </time></p>
  </header>

  <div class="post-content e-content" itemprop="articleBody">
    <blockquote>
  <p>According to Lawler, what is “the problem of technology”? What are the moral principles that he appeals to in deploying his argument? And, to what extent do you agree or disagree with his argument?</p>
</blockquote>

<p>The problem with technology, according to Lawler in his 2005 writ, “The Problem with Technology”, is that we cannot separate ourselves from it, and it that it serves us not only for better, but also for worse. Lawler simply explains the first point by saying that despite niche communities such as the Amish, most people use, or would use, all modern technologies available to them. For his second point, the most immediate moral principle that Lawler appeals to in his argument is rights. In this regard, Lawler is mostly positive. He claims that advanced, nearly omniscient technology will eliminate the dependency of people upon each other. Thus, people’s in general, negative rights will be safeguarded from one another. He claims further that positive rights will be better furnished than in present societies.</p>

<p>Not everything is great, however, as Lawler explains in another possibility. These rights may be secured, but they may only be the bare minimum, and in terms of justice, resources are allotted very differently. Only those that have sufficient technical prowess will maintain mastery over their environment. These people, referred to as “bourgeois bohemians”, or “bobos” will live artificial lives, obsessed with technology and control of others. They will live lives not measured by virtue and caring, but by wealth, influence, and control of their environment. They will, in turn, take this attitude out on their children and try to force them into the same mindset.</p>

<p>There are more problems with virtues than just with a few individuals, however. In terms of virtue, Lawler claims that all of society will degrade. This is because people will become so reliant on amoral (though not necessarily immoral) technology, rather than mutual reliance and a sense of community. Thus, people will no longer place value or find an incentive on seeking to become virtuous individuals. He believes some communities (especially religious or spiritual) will have a place in guiding people to virtuosity through their (perhaps ironically) constraining view which prompts internal and external reevaluation.</p>

<p>The same can be said of caring, whereby technology allows for much more extensive contact and communication, but makes relationships more distant, and the reasons for communication more shallow (with kin and kith being less necessary to get through life, especially compared to pre-modern times). Lawler takes modern social interaction as an example, wherein many have grown up without strong communal ties or interpersonal skills of necessity. Customers may treat staff as though they were their tools (or vice-versa, though capitalism discourages this), or parents may treat children as objects to be managed and educated until they are ready to bear the family name and status.</p>

<p>Lawler even presents a Kantian argument,  that future technology’s attempt provide leisure is a contradiction. Leisure, he explains, is an arbitrary lack of necessity for work/plan, whereas technology tries to provide a plan to “solve” this problem. All of this goes to show that technology may possibly be immoral, and the technology we are stuck with is not only for better, but for worse.</p>

<blockquote>
  <p>Suppose we were to create a true, computational artificial intelligence (with an AI functionally equivalent to our own self-conscious intelligence). What policies, laws, or regulations should we put into place to protect the AI and ourselves? What moral principles are at work in your account?</p>
</blockquote>

<p>If humankind were to develop an artificial intelligence functionally equivalent to our own self-conscious intelligence, many policies, laws, and regulations would have to be reworked in order to protect the AI and ourselves. In regards to this artificial being, by definition, we have only taken into account intelligence, not specifying a body nor the other factors that bind humans to the world, such as wants, needs, or instincts. This likely means that such a being - at first - has no intrinsic predisposition toward, really, anything. This being, within a sense, may live in a network or disk only as information, but with the power to do either great good or great harm. To this end, the first regulations should reach the very fundamental moral principle of all: caring (Yirgoyen, 2017).</p>

<p>By designing an artificial intelligence with caring, we may ensure that it has the ethical basis of all other intelligent creatures. Likely, this should be based on the strong sense of caring, where this artificial intelligence empathizes with the boons and banes of all other beings. This form of caring would likely lead to utilitarian action on behalf of the artificial being. Its being based on the weak sense of caring may simply encourage favoritism (which, for a being with such computational power and resources, could be highly consequential), although a weak sense of caring may simply mean prioritizing those who interact with it most, or some such scheme. Specific laws and policies would likely have to left up to reputable psychologists, sociologists, biologists, and neurologists.</p>

<p>With the basis for all ethical theories established, caring, we may now look to something with more specificity, such as rights. With the advent of human-level artificial intelligence, new civil rights laws will have to be drafted for artificial life (in a sense, a then unrepresented minority). More generally, this would extend to all self-aware life, so that both humans and artificial beings would be protected. These laws would likely mirror all the human rights laws we have grown accustomed to (though they would have notable changes, such as “the right to plainly parsable output” rather than speech. In other cases, regulations such as the right to privacy and ownership would become much more complex. Artificial life itself may, without prior regulation, have the capacity for infinite privacy. Using metamorphic code techniques, a being in software could rewrite itself to not only change its identity, but to literally change its being. Perhaps a form of read-only memory would have to be enforced by law prior to the birth of a new artificial being.</p>

<p>Finally, when we descend into the idea of justice regarding an artificial being, a whole slew of potential policies arise. To begin, American neuroscientist Sam Harris explains in his TED presentation (2016) that the ability of an artificial being to think, and thus do anything thereafter, is purely information processing. By a computer, information processing can happen at orders of magnitude faster than human thought. To understand this, this means that artificial intelligence would think, live (and “breathe” so to speak), making decisions equivalent to humans in a world that is essentially running in extremely slow motion. It may not have the body to react to real-time events, but it would think, feel, and know in an unfathomably slow world. This means it’s ability to make the correct decisions, to do research and lay plans (having access to all databases and unfathomable space to write, at such speeds) would be, as Harris puts it, godlike. The optimal - or <em>just</em> - distribution of goods and services could likely be calculated in polynomial time, perceivable by humans. There would be a potential for such an AI to design a (or perhaps the) utopia. Expectedly, before such an AI is ever born, policies across the world stage should be enacted to limit artificial intelligence evolution (such power could lead to a more frightening road than nuclear weapons).</p>

<blockquote>
  <p>How do computers make our lives both easier and worse? Give examples of this in your own life. Be sure that you define what you mean by both “easier” and “worse”, and use some ethical theory to assess how it is that you reach your conclusion.</p>
</blockquote>

<p>Computers are an enormous topic - especially now - with origins extending far back into the 1800s, so expectedly they have made life both easier and worse in many ways. To list a few ways, there are communication vs disconnection, convenience vs unappreciation, and entertainment vs patience. To quantify the tug-of-war between these various boons and banes, we may apply ethical theories such as caring, justice, rights, utilitarianism, and virtues.</p>

<p>To begin, we may rekindle the aforementioned argument of communication vs disconnection. First, in terms of caring, as Lawler (2005) has noted, we may communicate and express our cares, opinions, wants, respects, and such to a far broader audience. I personally keep this rather limited (for security reasons),  but I have met many who do so. Using computers, via social media, my friends, family and colleagues have broadcast messages at relatively close to light speed. For example, whether it’s about the rise of the new American administration, or the fall of his favorite fast food chain from grace, my friend Kurt from SJSU’s fencing club has expressed both. However, this has, as again Lawler has noted, made communication more shallow. For one example, when I see old - perhaps glorified - films of the American 1950s (take the Twilight Zone, for example), where even the most socially awkward folks are able to express themselves through a standardized, common, culture and really say what they mean - and hear what is meant - I am left in awe. In terms of justice (distribution of goods and services), computer communication has made demands for organizing social, economic, and political change unprecedented. For example, my friend Petr has explained to me the demand for change in the former Soviet Union, for spreading American good and services through computer networks. Perhaps for this same reason, I have also seen on the news within my lifetime, the instability of societies such as Brazil, China, and the whole Middle East, who are still adapting to changing communications.</p>

<p>Turning away from people-to-people interactions, and moving towards people-to-technology, we may measure how computers have made our lives more convenient but more unappreciative. In terms of utilitarianism, computers have had an overall positive effect on the population. For example, a few weeks ago when I had little food, I asked my roommate for waffles. In our society where computer driven machines mass produce food, he thought nothing of it, and granted me two waffles. Then, I pulled these from a freezer, which is driven by an embedded system (computer) to manage the temperature automatically. However, computers have taken a toll on appreciation, as Lawler notes with the example of air conditioning; I too have complained for lack or overabundance of heat, when once the general population was unfazed or accustomed to their 20 mile world. In terms of justice, the convenience of computers is actually a negative, while the unappreciation is a positive. Conveniences have rapidly become new essentials, such as embedded automobile safety systems, smart phones, refrigerators - especially the internet - and much more. Thus, in terms of justice, if the present distribution of goods and resources means that one cannot afford or effectively use these conveniences, then they will be at higher risk for destitution and inability. This is because traditional alternatives (respectively listed), such as less busy roads, public phones/phone booths, or roadway markets and dry food diets have disappeared, failing economically. For example, my friend Shane’s family, when in high school, could not afford these “basic” appliances, and to continue his education, his aunt took him to Oregon to live with her. Unappreciation is a positive in terms of justice, because those without will be quicker to raise their voice, to demand what in other lands may be considered the epitome of high life. This will also lead to further demand for future, more improved conveniences. In my personal experience, this is the reason for all the “first world problem” jokes I have encountered.</p>

<p>Leaving the realm of needs, and entering the realm of leisure, we may easily apply the ethical theories of virtue and rights to measure the betterment and worsening of life by computers. In terms of virtue, the distraction provided by computers has had a mixed, perhaps arbitrary, effect. A diverse selection of movies, games, hobbies, and places powered by computers has quickly encouraged open-mindedness. I myself became enthralled by historical knowledge and understanding from an early age, playing and watching media whose settings took place in many different eras and areas. I also continue to study and understand Russian language and culture (as just a fun hobby for a computer scientist in this era). The virtue of patience, however, has taken a heavy toll. Sitting alone, without stimulation from a computer screen, I have found myself and others bounce knees or look around with anxiety. In a sense, people have started to lose the virtue of self-satisfaction. Specifically in terms of rights, computers have left leisure generally worse off. Computers have prompted for - and extended - the powers of regimes to enforce censorship or control. For example, the games I purchased from the software distributor Steam are guarded by DRM, unseen in the earlier days of computing. More nefariously, computers have made it easier for regimes, such as North Korea, to force exposure to media, invalidating negative rights (in this regard, it is by nature hard for me to speak of my own experiences, not knowing what, aside from a few media outlets online, has been blocked from my own sight).</p>

<p>In many ways, computers have made life both easier and worse, including the positives and negatives of communication, convenience, and leisure. To understand what makes these areas “easier” or “worse” for people, we may enlist the aid of various ethical theories, such as caring, justice, rights, utilitarianism, and virtues. These ways and theories, however, are not the limit to computers’ impact on life. For example, we have not even begun to explore education vs practical inexperience, health benefits vs poor lifestyles, or security vs risk in the age of computation.</p>

<h2 id="works-cited">Works Cited</h2>

<p>Harris, Sam. “Can We Build AI without Losing Control over It?” Ted. British Columbia, Canada, Vancouver. 6 May 2017. YouTube. Web. 19 May 2017.</p>

<p>Lawler, Peter Augustine. “The Problem of Technology. (Contemporary Perspectives).” Perspectives on Political Science 34.3th ser. 125.10 (2005): 1-9. Expanded Academic ASAP [Gale]. Web. 19 May 2017.</p>

<p>Yrigoyen, Kyle. Notes to All Ethical Theories. San Jose: Canvas, 8 May 2017. PDF.</p>

  </div><a class="u-url" href="/2017/05/Computers-Ethics-and-Society.html" hidden></a>
</article>

      </div>
    </main><footer class="site-footer h-card">
  <data class="u-url" href="/"></data>

  <div class="wrapper">

    <h2 class="footer-heading">HvanB</h2>

    <div class="footer-col-wrapper">
      <div class="footer-col footer-col-1">
        <ul class="contact-list">
          <li class="p-name">HvanB</li><li><a class="u-email" href="mailto:hvanb@protonmail.com">hvanb@protonmail.com</a></li></ul>
      </div>

      <div class="footer-col footer-col-2"><ul class="social-media-list"><li><a href="https://github.com/DoughKnight"><svg class="svg-icon"><use xlink:href="/assets/minima-social-icons.svg#github"></use></svg> <span class="username">DoughKnight</span></a></li><li><a href="https://www.linkedin.com/in/T.B.A."><svg class="svg-icon"><use xlink:href="/assets/minima-social-icons.svg#linkedin"></use></svg> <span class="username">T.B.A.</span></a></li><li><a href="https://youtube.com/T.B.A."><svg class="svg-icon"><use xlink:href="/assets/minima-social-icons.svg#youtube"></use></svg> <span class="username">T.B.A.</span></a></li></ul>
</div>

      <div class="footer-col footer-col-3">
        <p>Software Development in the Silicon Slopes</p>
      </div>
    </div>

  </div>

</footer>
</body>

</html>
